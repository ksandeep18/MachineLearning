{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ0KBgrX6gNRQVtQMXK2++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksandeep18/MachineLearning/blob/main/Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a crucial Python library for data manipulation and analysis, frequently used in data science roles.  Here's a breakdown of key concepts for placement preparation:\n",
        "\n",
        "**1. Core Data Structures:**\n",
        "\n",
        "* **Series:** A one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.).  Think of it as a column in a table. Key aspects include indexing (label-based and integer-based) and data type inference.\n",
        "* **DataFrame:** A two-dimensional labeled data structure with columns of potentially different types.  This is the workhorse of Pandas and analogous to a spreadsheet or SQL table.  Understanding how to create, manipulate, and query DataFrames is essential.\n",
        "\n",
        "**2. Data Input/Output:**\n",
        "\n",
        "* Pandas excels at reading and writing data from various sources: CSV, Excel files, SQL databases, JSON, and more.  Be prepared to demonstrate proficiency in these operations, including specifying delimiters, handling headers, and managing missing data during import.\n",
        "* `pd.read_csv()`, `pd.read_excel()`, `pd.read_sql()`, `pd.to_csv()` are common methods.  Understand their parameters.\n",
        "\n",
        "\n",
        "**3. Data Selection and Filtering:**\n",
        "\n",
        "* **Indexing and Selecting Data:**  `.loc` (label-based) and `.iloc` (integer-based) are fundamental for accessing specific rows and columns.  Practice different slicing techniques.\n",
        "* **Boolean Indexing:**  Filtering data based on conditions is a very important skill.  Understand how to create boolean masks and apply them to DataFrames to select subsets of data.\n",
        "* **Conditional Selection:**  Using comparison operators (>, <, ==, !=) and logical operators (&, |, ~) to filter rows.\n",
        "\n",
        "**4. Data Cleaning and Preprocessing:**\n",
        "\n",
        "* **Handling Missing Data:** `isnull()`, `notnull()`, `dropna()`, `fillna()`.  Learn how to identify, remove, or impute missing values appropriately.\n",
        "* **Data Type Conversion:**  `astype()` is useful for converting column data types (e.g., string to numeric).\n",
        "* **Duplicate Handling:** `duplicated()`, `drop_duplicates()`.  Identify and remove duplicate rows.\n",
        "\n",
        "**5. Data Wrangling and Transformation:**\n",
        "\n",
        "* **Grouping and Aggregation:**  `groupby()` allows for grouping data based on one or more columns and applying aggregate functions (e.g., sum, mean, count, min, max).\n",
        "* **Applying Functions:**  `.apply()` and `.map()` are powerful for applying custom functions to data.\n",
        "* **Pivot Tables:**  Create summary tables for data analysis using pivot and crosstab operations.\n",
        "* **Joining/Merging DataFrames:**  `merge()` and `join()` to combine DataFrames based on shared columns.\n",
        "\n",
        "**6. Data Visualization (Integration with Matplotlib/Seaborn):**\n",
        "\n",
        "* While not strictly Pandas, understanding how to visualize data using Pandas in conjunction with plotting libraries like Matplotlib and Seaborn is a significant advantage.  Know how to create histograms, scatter plots, bar charts, and more.\n",
        "\n",
        "\n",
        "**7. Performance Considerations:**\n",
        "\n",
        "* Be aware of common performance bottlenecks and strategies for optimizing Pandas operations, especially with large datasets.\n",
        "\n",
        "\n",
        "**Placement Tip:**  Practice using real-world datasets (Kaggle, UCI Machine Learning Repository) to build your portfolio and showcase your Pandas skills.  Be prepared to discuss your approach to data cleaning, analysis, and visualization in interviews.\n"
      ],
      "metadata": {
        "id": "TuD1WgALWBni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Series and DataFrames\n",
        "# Create a Series\n",
        "data = [10, 20, 30, 40, 50]\n",
        "s = pd.Series(data)\n",
        "print(\"Series:\\n\", s)\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "        'Age': [25, 30, 22, 28],\n",
        "        'City': ['New York', 'London', 'Paris', 'Tokyo']}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"\\nDataFrame:\\n\", df)\n",
        "\n",
        "\n",
        "# 2. Data Input/Output\n",
        "# Read a CSV file (replace with your file path)\n",
        "# df_csv = pd.read_csv(\"your_file.csv\")\n",
        "# print(\"\\nData from CSV:\\n\", df_csv.head())\n",
        "\n",
        "\n",
        "# 3. Data Selection and Filtering\n",
        "# .loc (label-based)\n",
        "print(\"\\n.loc:\\n\", df.loc[0:1, 'Name':'Age']) # select rows 0 to 1 (inclusive), columns 'Name' to 'Age'\n",
        "\n",
        "# .iloc (integer-based)\n",
        "print(\"\\n.iloc:\\n\", df.iloc[0:2, 0:2]) # Select rows 0 to 1, columns 0 to 1\n",
        "\n",
        "# Boolean Indexing\n",
        "print(\"\\nBoolean Indexing:\\n\", df[df['Age'] > 25])  # Filter rows where Age is greater than 25\n",
        "\n",
        "\n",
        "# 4. Data Cleaning\n",
        "# Handling missing data\n",
        "df_with_nan = pd.DataFrame({'A': [1, 2, np.nan], 'B': [4, np.nan, 6]})\n",
        "print(\"\\nDataFrame with NaN:\\n\", df_with_nan)\n",
        "print(\"\\nDrop NaN rows:\\n\", df_with_nan.dropna())\n",
        "print(\"\\nFilling NaN with 0:\\n\", df_with_nan.fillna(0))\n",
        "\n",
        "# Data Type Conversion\n",
        "df['Age'] = df['Age'].astype(float) # Converting column to different type\n",
        "print(\"\\nModified data types:\\n\", df.dtypes)\n",
        "\n",
        "#Duplicate Handling\n",
        "df_duplicate = pd.DataFrame({'col1': [1, 2, 2, 3], 'col2': ['a', 'b', 'b', 'c']})\n",
        "print(\"\\nDataFrame with duplicates:\\n\",df_duplicate)\n",
        "print(\"\\nRemoved duplicates:\\n\", df_duplicate.drop_duplicates())\n",
        "\n",
        "\n",
        "# 5. Data Wrangling and Transformation\n",
        "# Grouping and Aggregation\n",
        "print(\"\\nGrouped data:\\n\", df.groupby('City')['Age'].mean())  # Calculate the mean Age per City\n",
        "\n",
        "# Applying Functions\n",
        "df['Age_squared'] = df['Age'].apply(lambda x: x**2)\n",
        "print(\"\\nAge squared:\\n\",df)\n",
        "\n",
        "\n",
        "# 6. Visualization\n",
        "# import matplotlib.pyplot as plt\n",
        "# df.plot(x='Name', y='Age', kind='bar')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# 7. Performance (Example with large data)\n",
        "# For very large datasets, consider using optimized libraries like Dask.\n",
        "\n",
        "# Placement Tip: Work with Kaggle datasets.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaN4cHHjWRDq",
        "outputId": "9dae743c-172a-45db-d2d5-7fc987f15c12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series:\n",
            " 0    10\n",
            "1    20\n",
            "2    30\n",
            "3    40\n",
            "4    50\n",
            "dtype: int64\n",
            "\n",
            "DataFrame:\n",
            "       Name  Age      City\n",
            "0    Alice   25  New York\n",
            "1      Bob   30    London\n",
            "2  Charlie   22     Paris\n",
            "3    David   28     Tokyo\n",
            "\n",
            ".loc:\n",
            "     Name  Age\n",
            "0  Alice   25\n",
            "1    Bob   30\n",
            "\n",
            ".iloc:\n",
            "     Name  Age\n",
            "0  Alice   25\n",
            "1    Bob   30\n",
            "\n",
            "Boolean Indexing:\n",
            "     Name  Age    City\n",
            "1    Bob   30  London\n",
            "3  David   28   Tokyo\n",
            "\n",
            "DataFrame with NaN:\n",
            "      A    B\n",
            "0  1.0  4.0\n",
            "1  2.0  NaN\n",
            "2  NaN  6.0\n",
            "\n",
            "Drop NaN rows:\n",
            "      A    B\n",
            "0  1.0  4.0\n",
            "\n",
            "Filling NaN with 0:\n",
            "      A    B\n",
            "0  1.0  4.0\n",
            "1  2.0  0.0\n",
            "2  0.0  6.0\n",
            "\n",
            "Modified data types:\n",
            " Name     object\n",
            "Age     float64\n",
            "City     object\n",
            "dtype: object\n",
            "\n",
            "DataFrame with duplicates:\n",
            "    col1 col2\n",
            "0     1    a\n",
            "1     2    b\n",
            "2     2    b\n",
            "3     3    c\n",
            "\n",
            "Removed duplicates:\n",
            "    col1 col2\n",
            "0     1    a\n",
            "1     2    b\n",
            "3     3    c\n",
            "\n",
            "Grouped data:\n",
            " City\n",
            "London      30.0\n",
            "New York    25.0\n",
            "Paris       22.0\n",
            "Tokyo       28.0\n",
            "Name: Age, dtype: float64\n",
            "\n",
            "Age squared:\n",
            "       Name   Age      City  Age_squared\n",
            "0    Alice  25.0  New York        625.0\n",
            "1      Bob  30.0    London        900.0\n",
            "2  Charlie  22.0     Paris        484.0\n",
            "3    David  28.0     Tokyo        784.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: take a sample data set and show how to work with numpy and pandas in projects... a small sample project type only\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "data = {'Product': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
        "        'Sales': [100, 150, 120, 200, 180, 110],\n",
        "        'Region': ['North', 'South', 'North', 'East', 'South', 'West']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Basic Data Exploration\n",
        "print(\"First 5 rows:\\n\", df.head())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "print(\"\\nSummary statistics:\\n\", df.describe())\n",
        "\n",
        "# 2. Data Cleaning (Handling missing values - example)\n",
        "# Let's assume some 'Sales' data is missing. We'll replace them with the mean.\n",
        "df['Sales'].fillna(df['Sales'].mean(), inplace=True)\n",
        "\n",
        "# 3. Data Manipulation\n",
        "# Calculate total sales per product\n",
        "product_sales = df.groupby('Product')['Sales'].sum()\n",
        "print(\"\\nTotal Sales per product:\\n\", product_sales)\n",
        "\n",
        "# 4. Data Filtering\n",
        "# Find products with sales greater than 150\n",
        "high_sales_products = df[df['Sales'] > 150]\n",
        "print(\"\\nProducts with sales > 150:\\n\", high_sales_products)\n",
        "\n",
        "# 5. Data Transformation\n",
        "# Create a new column 'SalesCategory'\n",
        "def categorize_sales(sales):\n",
        "    if sales < 150:\n",
        "        return 'Low'\n",
        "    elif sales < 200:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "df['SalesCategory'] = df['Sales'].apply(categorize_sales)\n",
        "print(\"\\nDataFrame with SalesCategory:\\n\", df)\n",
        "\n",
        "# 6. Using NumPy for calculations\n",
        "# Calculate the mean sales using NumPy\n",
        "sales_array = df['Sales'].to_numpy()  # Convert pandas Series to numpy array\n",
        "mean_sales_numpy = np.mean(sales_array)\n",
        "print(\"\\nMean sales (NumPy):\", mean_sales_numpy)\n",
        "\n",
        "\n",
        "#7. Pivot Tables (Example)\n",
        "pivot_table = pd.pivot_table(df, values='Sales', index='Product', columns='Region', aggfunc='sum', fill_value=0)\n",
        "print(\"\\nPivot Table:\\n\",pivot_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGRMMhMBWigY",
        "outputId": "f9e9f000-e77f-43e3-cdb1-2747ca892768"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "   Product  Sales Region\n",
            "0       A    100  North\n",
            "1       B    150  South\n",
            "2       A    120  North\n",
            "3       C    200   East\n",
            "4       B    180  South\n",
            "\n",
            "Data types:\n",
            " Product    object\n",
            "Sales       int64\n",
            "Region     object\n",
            "dtype: object\n",
            "\n",
            "Summary statistics:\n",
            "             Sales\n",
            "count    6.000000\n",
            "mean   143.333333\n",
            "std     40.331956\n",
            "min    100.000000\n",
            "25%    112.500000\n",
            "50%    135.000000\n",
            "75%    172.500000\n",
            "max    200.000000\n",
            "\n",
            "Total Sales per product:\n",
            " Product\n",
            "A    330\n",
            "B    330\n",
            "C    200\n",
            "Name: Sales, dtype: int64\n",
            "\n",
            "Products with sales > 150:\n",
            "   Product  Sales Region\n",
            "3       C    200   East\n",
            "4       B    180  South\n",
            "\n",
            "DataFrame with SalesCategory:\n",
            "   Product  Sales Region SalesCategory\n",
            "0       A    100  North           Low\n",
            "1       B    150  South        Medium\n",
            "2       A    120  North           Low\n",
            "3       C    200   East          High\n",
            "4       B    180  South        Medium\n",
            "5       A    110   West           Low\n",
            "\n",
            "Mean sales (NumPy): 143.33333333333334\n",
            "\n",
            "Pivot Table:\n",
            " Region   East  North  South  West\n",
            "Product                          \n",
            "A           0    220      0   110\n",
            "B           0      0    330     0\n",
            "C         200      0      0     0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f2501287fbaa>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Sales'].fillna(df['Sales'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6QX7b-3KV_x1"
      }
    }
  ]
}